## Détecter la désinformation climatique 📝   
## *et rester cohérent avec un modèle frugal* 
  
---  
Le Wagon — Data Science #1820

## DEPART 🚀  
**🎯 Objectif**  
Développer un modèle *performant* (% accuracy) et *frugal* (Wh) pour la détection de désinformation lié au climat dans des textes.

**📊 Données**  
[6k citations (EN) catégorisées suivant 8 étiquettes de désinformation](https://huggingface.co/datasets/QuotaClimat/frugalaichallenge-text-train)  
Train : 4,87k lignes  
Test : 1,22k lignes  

## PISTES 🗺️  
- Fine tuning de modèles : pré-LLM (ie: BERT), petit Language Model à fine-tuner (ie: Qwen)
- Finetuning des embeddings
- Finetuning de classifier : Random forests, Log regression, MLP, ..
- *Et bien d’autres*  🥰

## ARRIVEE 🏁  
![Alt Text](https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExaDRzYzNwY3NwMHJnMjhwejA3c2VlcG5pdGJjd3Zua2NpdmRza2VrZiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/yxx6hlbDZ4Q6MX3rS4/giphy.gif)  
